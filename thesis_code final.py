# -*- coding: utf-8 -*-
"""thesis code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IWEbx4EEeh5wgt2kNFe0U6z_ObZyFR1R
"""

pip install pandas

pip install matplotlib

pip install scipy

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

path = '/content/ACID_Final_Data.csv'
#only keeping necessary columns
keep = ['condition','gender','GAD_1','GAD_2','GAD_3','GAD_4','GAD_5','GAD_6','GAD_7','msh_1','msh_2','msh_3','msh_4','msh_5','ipd','ipd_setting','postssq_ts','ssqts_change']
def load_processed(path,keep,skip_first=13):
    base = pd.read_csv(path)
    out = base.loc[:,keep].iloc[skip_first:].reset_index(drop=True).copy()
    return base, out
base,df = load_processed(path,keep)

print("Rows:",len(df),'Colounns', df.shape[1])

#changing the range from 1-4 to 0-3
gad_cols = ['GAD_1','GAD_2','GAD_3','GAD_4','GAD_5','GAD_6','GAD_7']
df[gad_cols] = df[gad_cols].apply(pd.to_numeric,errors = 'coerce')
map_dict = {1:0, 2:1, 3:2, 4:3}
df[gad_cols] = df[gad_cols].apply(lambda col: col.map(map_dict).fillna(col))
df_recode = df.to_csv("ACID_Final_Data_recode",index= False)

#male =0,female =1
df['gender']= df['gender'].replace({1:0,2:1})

#classifying each person's anxiety
df['GAD_Total'] = df[gad_cols].sum(axis=1)
def categorize_anxiety(score):
    if pd.isna(score):
        return None
    elif score <=4:
        return 'Minimal anxiety'
    elif score <=9:
        return 'Mild anxiety'
    elif score <=14:
        return 'Moderate anxiety'
    else:
        return 'Severe anxiety'

df['GAD_Level'] = df['GAD_Total'].apply(categorize_anxiety)

#distribution of scores
plt.figure(figsize=(8,5))
plt.hist(df['GAD_Total'],bins =22,edgecolor='black',color='pink')
plt.title('distribution of GAD-7 Total Scores')
plt.xlabel('GAD-7 Total Score (0-21)')
plt.ylabel('number of participants')
plt.xticks(range(0,22))
plt.grid(axis='y',alpha=0.3)
plt.show()

#0-1 normalize ssqts_change
df['ssqts_change']= pd.to_numeric(df['ssqts_change'],errors='coerce')
df['ssqts_change_norm']= (df['ssqts_change']-df['ssqts_change'].min())/(df['ssqts_change'].max()-df['ssqts_change'].min())

#plot for distribution of cybersickness change
plt.figure(figsize=(8,5))
plt.hist(df['ssqts_change_norm'],bins =20,edgecolor='black',color='pink')
plt.title('distribution of cybersickness change')
plt.xlabel('ssq_changed (normalized)')
plt.ylabel('number of participants')
plt.xticks(np.linspace(0,1,11))
plt.xlim(0,1)
plt.grid(axis='y',alpha=0.3)
plt.show()

#classifying postssq scores
df['postssq_ts'] =pd.to_numeric(df['postssq_ts'],errors = 'coerce')
if 'cybersick_binary_15' not in df.columns:
    df['cybersick_binary_15'] = (df['postssq_ts']>=15).astype(int)

def ssq_severity(ts):
    if pd.isna(ts):
        return None
    if ts< 15:
        return 'Minimal'
    if ts <40:
        return 'Mild'
    if ts <60:
        return 'Moderate'
    return 'Severe'
if 'ssq_severity' not in df.columns:
    df['ssq_severity'] = df['postssq_ts'].apply(ssq_severity)

#one hot encoding condition column
df = pd.get_dummies(df, columns =['condition'], prefix='cond',drop_first=True)

pip install scikit-learn

#data split
from sklearn.model_selection import train_test_split
X = df[['gender','GAD_Total','cond_2','cond_3']]
y = df['cybersick_binary_15']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

pip install seaborn

#correlation matrix
import seaborn as sns

corr = df[['GAD_Total','gender','cybersick_binary_15']].corr()

plt.figure(figsize=(6,4))
sns.heatmap(corr,annot=True,fmt= ".2f",cmap='coolwarm',vmin=-1,vmax=1)
plt.title('correlation matrix:anxiety,gender, and cybersickness')
plt.show()

#baseline  model
from sklearn.dummy import DummyClassifier
from sklearn.metrics import f1_score

dummy = DummyClassifier(strategy="most_frequent")

dummy.fit(X,y)
baseline_pred = dummy.predict(X)

baseline_macro_f1 = f1_score(y,baseline_pred,average='macro')
print("baseline macro F1:",baseline_macro_f1)

#logistic regression model
from sklearn.linear_model import LogisticRegression
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import StratifiedKFold,cross_val_score

L_g = LogisticRegression(max_iter=1000)
L_g_pipeline = Pipeline([('smote',SMOTE(random_state=42)),('model',L_g)])

cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)

scores_L_g = cross_val_score(L_g_pipeline,X,y,cv=cv,scoring='f1_macro')
print("Logistics Regression Macro F1 Scores:", scores_L_g)
print ("Mean Macro F1:", scores_L_g.mean())

lr_full = LogisticRegression(max_iter=1000)
lr_full.fit(X, y)
probs = lr_full.predict_proba(X)[:,1]
ll_model = np.sum(y*np.log(probs)+(1-y)*np.log(1-probs))
p_null = np.mean(y)
ll_null = np.sum(y*np.log(p_null)+(1-y)*np.log(1-p_null))
mcfadden_r2 =1-(ll_model/ll_null)

print("McFadden's Pseudo R^2:",mcfadden_r2)

pip install imblearn

#random forest model
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=500,max_depth= None,class_weight= None,random_state=42)
pipeline_rf = Pipeline([('smote',SMOTE(random_state=42)),('model',rf)])

cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)

scores_rf = cross_val_score(pipeline_rf,X,y,cv=cv,scoring='f1_macro')
print(scores_rf,scores_rf.mean())

pipeline_rf.fit(X,y)

#LightGBM model
from lightgbm import LGBMClassifier
lgbm_model = LGBMClassifier(n_estimators = 300,max_depth = 3, learning_rate = 0.05,
                          subsample = 0.8, colsample_bytree = 0.8, random_state = 42 )

lgbm_pipeline = Pipeline([('smote', SMOTE(random_state=42)), ('model',lgbm_model)])

cv =StratifiedKFold(n_splits=5,shuffle=True,random_state=42)

lgbm_pipeline.fit(X,y)
lgbm_scores = cross_val_score(lgbm_pipeline,X,y,scoring='f1_macro',cv=cv)

print("LightGBM Macro F1 Scores:", lgbm_scores)
print("Mean Macro F1:", lgbm_scores.mean())

pip install lightgbm

#confusion matrix for each model
from sklearn.metrics import confusion_matrix
models = {
    "Logistic Regression": lr_full,
    "Random Forest": pipeline_rf,
    "LightGBM":lgbm_pipeline
}

plt.figure(figsize=(12,4))
i=1

for name, model in models.items():
    plt.subplot(1,3,i)
    y_pred = model.predict(X)
    cm = confusion_matrix(y,y_pred)
    sns.heatmap(cm,annot=True,fmt='d',cmap="Blues")
    plt.title(name)
    plt.xlabel('predicted')
    plt.ylabel('actual')
    i+=1
plt.tight_layout()
plt.show()

#Table 1 : average over all cross-validation folds for each model

results_df = pd.DataFrame({
    "Model": ["Logistic Regression", "Random Forest", "LightGBM"],
    "Fold 1": [scores_L_g[0], scores_rf[0], lgbm_scores[0]],
    "Fold 2": [scores_L_g[1], scores_rf[1], lgbm_scores[1]],
    "Fold 3": [scores_L_g[2], scores_rf[2], lgbm_scores[2]],
    "Fold 4": [scores_L_g[3], scores_rf[3], lgbm_scores[3]],
    "Fold 5": [scores_L_g[4], scores_rf[4], lgbm_scores[4]],
})


results_df["Mean Macro F1"] = results_df[["Fold 1","Fold 2","Fold 3","Fold 4","Fold 5"]].mean(axis=1)

results_df

#Table 2 : mean macro F1-scores for each model in relation to the majority-class baseline
baseline_f1 = round(baseline_macro_f1,3)

logreg_f1 = round(0.643763,3)
lightgbm_f1 =round(0.547885,3)
rf_f1 = round(0.46726,3)

table_data = {
    "Model": ["Baseline(Most Frequent)","Logistic Regression","LightGBM","Random Forest"],
    "Mean Macro F1" : [baseline_f1,logreg_f1,lightgbm_f1,rf_f1],
    "Improvement over Baseline":[
        round(0,3),
        round(logreg_f1 - baseline_f1,3),
        round(lightgbm_f1 - baseline_f1,3),
        round(rf_f1 - baseline_f1,3),
    ]
}
performance_table = pd.DataFrame(table_data)
performance_table

# precision-recall curve for each model
from sklearn.metrics import precision_recall_curve

plt.figure(figsize=(7,5))

models = {
    "Logistic Regression": lr_full,
    "Random Forest": pipeline_rf,
    "LightGBM":lgbm_pipeline
}

for name, model in models.items():
  y_scores = model.predict_proba(X)[:,1]
  precision,recall,_ = precision_recall_curve(y,y_scores)
  plt.plot(recall,precision,label =name)
plt.xlabel("recall")
plt.ylabel("precision")
plt.title("precision-recall curves")
plt.legend
plt.grid(True,alpha =0.3)
plt.show()

#distribution of the binary cybersickness labels
plt.figure(figsize=(6,4))
sns.countplot(x=y,palette ="pastel")
plt.xlabel("class(0 = no cybersickness, 1 = cybersickness)")
plt.ylabel("count")
plt.title("distribution of cybersickness labels")
plt.legend
plt.grid(axis= 'y',alpha =0.3)
plt.show()

#Table 3: Wald significance test results

import statsmodels.api as sm

X_fixed = X.copy()
X_fixed['cond_2']=X_fixed['cond_2'].astype(int)
X_fixed['cond_3']=X_fixed['cond_3'].astype(int)

X_stats = sm.add_constant(X_fixed)

logit_model= sm.Logit(y,X_stats)
result = logit_model.fit()

print(result.summary())

